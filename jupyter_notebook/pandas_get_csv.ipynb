{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "speeds = pd.DataFrame(\n",
    "    [\n",
    "        (\"bird\", \"Falconiformes\", 389.0),\n",
    "        (\"bird\", \"Psittaciformes\", 24.0),\n",
    "        (\"mammal\", \"Carnivora\", 80.2),\n",
    "        (\"mammal\", \"Primates\", np.nan),\n",
    "        (\"mammal\", \"Carnivora\", 58),\n",
    "    ],\n",
    "    index=[\"falcon\", \"parrot\", \"lion\", \"monkey\", \"leopard\"],\n",
    "    columns=(\"class\", \"order\", \"max_speed\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"A\")\n",
    "for key, item in grouped:\n",
    "    print(grouped.get_group(key))\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"A\")\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"A\")\n",
    "grouped\n",
    "grouped.apply(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index([\"A\", \"B\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "print(dt.datetime(2018, 7, 17, 0, 15))\n",
    "\n",
    "data = [    (dt.datetime(2018, 7, 17, 0, 15), dt.datetime(2018, 7, 17, 0, 30), 'sleep'),\n",
    "            (dt.datetime(2018, 7, 17, 0, 30), dt.datetime(2018, 7, 17, 0, 45), 'eat'),\n",
    "            (dt.datetime(2018, 7, 17, 0, 45), dt.datetime(2018, 7, 17, 1, 0), 'work'),\n",
    "            (dt.datetime(2018, 7, 17, 1, 0), dt.datetime(2018, 7, 17, 1, 30), 'sleep'),\n",
    "            (dt.datetime(2018, 7, 17, 1, 15), dt.datetime(2018, 7, 17, 1, 30), 'eat'), \n",
    "            (dt.datetime(2018, 7, 17, 1, 30), dt.datetime(2018, 7, 17, 1, 45), 'work')\n",
    "        ]\n",
    "\n",
    "mdates.date2num(dt.datetime(2018, 7, 17, 0, 15))\n",
    "\n",
    "a = mdates.date2num(dt.datetime(2018, 7, 17, 0, 15)) + 0.5\n",
    "\n",
    "print(mdates.num2date(a))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "a = 19494.82361111111 + 53/60/24\n",
    "print(mdates.num2date(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = '/Users/qingjie/Library/Application Support/Radar/Downloads/Problem/107771556/Final_0607_PWYS_SMT_P1_Coex_offline_daily_report/SMT_All'\n",
    "\n",
    "with os.scandir(dir_path) as it:\n",
    "    for entry in it:\n",
    "        if entry.is_dir():\n",
    "            print(entry.name, entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_path = input(\"drag the folder: \")\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_path = '/Users/qingjie/Library/Application Support/Radar/Downloads/Problem/107771556/Final_0607_PWYS_SMT_P1_Coex_offline_daily_report/SMT_All'\n",
    "\n",
    "to_be_combined_csv_path = []\n",
    "\n",
    "# with os.scandir(dir_path) as dir1:\n",
    "#     for entry1 in dir1:\n",
    "#         if entry1.is_dir():\n",
    "#             with os.scandir(entry1) as dir2:\n",
    "#                 for entry2 in dir2:\n",
    "#                     if entry2.name[0].isdigit() & entry2.name.endswith(\".csv\") :\n",
    "#                         to_be_combined_csv_path.append(entry2.path)\n",
    "\n",
    "# find all resut csv in a ceratin foler and its sub folder\n",
    "to_be_find_path = dir_path + \"/**/[0-9]*.csv\"\n",
    "for f in glob.glob(to_be_find_path, recursive=True):\n",
    "    to_be_combined_csv_path.append(f)\n",
    "\n",
    "# The first file set as base to be merged with others\n",
    "# read only certain columns we want\n",
    "wanted_columns = []\n",
    "for i in range (0,28,1):\n",
    "    wanted_columns.append(i)\n",
    "\n",
    "# for rest of csv, we only want the index = 7 row, which contains needed data\n",
    "wanted_rows = [5]\n",
    "\n",
    "# # The scond row as header, header = 1\n",
    "# df_csv_1 = pd.read_csv(to_be_combined_csv_path[0], header=1, usecols = wanted_columns, skiprows=lambda x: x not in wanted_rows)\n",
    "# # df_csv_1\n",
    "\n",
    "# initialize df_concat as the first csv datafrme, \n",
    "df_concat = pd.read_csv(to_be_combined_csv_path[0], header=1, usecols = wanted_columns, skiprows=[2,3,4,5,6])\n",
    "\n",
    "# df_csv_next = pd.read_csv(to_be_combined_csv_path[1], header=1, usecols = wanted_columns, skiprows=[2,3,4,5,6])\n",
    "# df_concat = pd.concat([df_concat, df_csv_next], ignore_index=True)\n",
    "\n",
    "for file_index, file in enumerate(to_be_combined_csv_path):\n",
    "    if file_index + 1 < len(to_be_combined_csv_path):\n",
    "        df_csv_next = pd.read_csv(to_be_combined_csv_path[file_index+1], header=1, usecols = wanted_columns, skiprows=[2,3,4,5,6])\n",
    "        df_concat = pd.concat([df_concat, df_csv_next], ignore_index=True)\n",
    "\n",
    "df_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.loc[0, 'product']\n",
    "df_concat.loc[0, 'STATION_TYPE'].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
